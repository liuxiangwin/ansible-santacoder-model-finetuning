{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29daf26-2aae-4127-a273-1fbf490b113c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine-tune SantaCoder on YAML\n",
    "Sources:\n",
    "* https://github.com/loubnabnl/santacoder-finetuning\n",
    "* https://colab.research.google.com/drive/1UMjeXHwOldpLnWjdm1499o2IYy0RgeTw?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f655fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ca5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m284.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets in /opt/app-root/lib/python3.9/site-packages (8.1.1)\n",
      "Requirement already satisfied: torch in /opt/app-root/lib/python3.9/site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m273.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m217.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.4/773.4 kB\u001b[0m \u001b[31m292.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m200.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (15.0.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m258.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/app-root/lib/python3.9/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.8/193.8 kB\u001b[0m \u001b[31m271.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: lit in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch) (17.0.6)\n",
      "Requirement already satisfied: cmake in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.28.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: stack-data in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/app-root/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/app-root/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pure-eval in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow-hotfix, multiprocess, huggingface-hub, tokenizers, transformers, datasets\n",
      "Successfully installed datasets-2.18.0 huggingface-hub-0.21.4 multiprocess-0.70.16 pyarrow-hotfix-0.6 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.2 xxhash-3.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (2.0.1+cu118)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/app-root/lib/python3.9/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/app-root/lib/python3.9/site-packages (from accelerate) (0.21.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: lit in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.6)\n",
      "Requirement already satisfied: cmake in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.27.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets ipywidgets torch\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3adb3c-ec83-4279-8ee2-040e7af94945",
   "metadata": {},
   "source": [
    "### Log in to HuggingFace to access The Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c37d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /opt/app-root/src/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "# Note: Prefer notebook_login() but this was not prompting properly\n",
    "login(token=os.environ.get('HUGGINGFACE_TOKEN'))\n",
    "#print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc8eda-264c-43d1-9050-8a3184c1d11b",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0eae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    "    set_seed\n",
    ")\n",
    "from dataset import ConstantLengthDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea840e5f-d43d-4578-94f2-6145367d1710",
   "metadata": {},
   "source": [
    "### Specify the pre-trained model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2f7129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"bigcode/santacoder\"\n",
    "dataset_id = \"bigcode/the-stack-dedup\"\n",
    "data_dir = \"data/yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3348c67-027a-4da4-b76f-bbc83cde63ef",
   "metadata": {},
   "source": [
    "### Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552fcc77-81a2-4aeb-ac48-9a9c3914be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e678c1-6891-49d8-a34f-43e0cbd26d50",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d92585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e570e0bd-d2ed-42c3-a493-01dd247ea525",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Use the first 10% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee85663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728013c3c774435c824bc61c88ed5cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_id, data_dir=data_dir, split='train[:10%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0adcd-9c03-4498-898d-27e5d06ea5c8",
   "metadata": {},
   "source": [
    "### Calculate characters per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c27370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62de2e9f4314521be65e54b2a9cb27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3514 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4527346671628827\n"
     ]
    }
   ],
   "source": [
    "examples, total_characters, total_tokens = 500, 0, 0\n",
    "\n",
    "for _, example in tqdm(zip(range(examples), iter(dataset)), total=examples):\n",
    "    total_characters += len(example['content'])\n",
    "    total_tokens += len(tokenizer(example['content']).tokens())\n",
    "\n",
    "characters_per_token = total_characters / total_tokens\n",
    "print(characters_per_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884c87e-45bb-468e-84b4-16e4cc2d8e4b",
   "metadata": {},
   "source": [
    "### Create a test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0121c28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525566, 2642)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.005, shuffle=False, seed=555)\n",
    "train_ds = dataset[\"train\"]\n",
    "valid_ds = dataset[\"test\"]\n",
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a47a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(seed=555)\n",
    "\n",
    "train_dataset = ConstantLengthDataset(\n",
    "        tokenizer, train_ds, infinite=True, seq_length=1024, chars_per_token=characters_per_token \n",
    "    )\n",
    "valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer, valid_ds, infinite=False, seq_length=1024, chars_per_token=characters_per_token\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f118f-f251-466d-bebb-2d5e62b01f14",
   "metadata": {},
   "source": [
    "### Define the training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce427ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir=\"santacoder-finetuned-the-stack-yaml\",\n",
    "        dataloader_drop_last=True,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"adafactor\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "#        max_steps=5000,\n",
    "        max_steps=1000,\n",
    "        eval_steps=500,\n",
    "        save_steps=500,\n",
    "        logging_steps=10,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        learning_rate=5e-5,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.05,\n",
    "        fp16=False,\n",
    "        push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ffb5fe-3619-4a3a-9009-1259622f3fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu118\n",
      "CUDA is available.\n",
      "Number of GPU: 1\n",
      "Current Device : <function current_device at 0x7fe603715a60>\n",
      "Device 0: NVIDIA A10G\n",
      "_CudaDeviceProperties(name='NVIDIA A10G', major=8, minor=6, total_memory=22502MB, multi_processor_count=80)\n",
      "Memory GB: 21.98 GB\n",
      "GPU Allocated: 4.31 GB\n",
      "GPU Cached:    10.17 GB\n",
      "<function _get_device_index at 0x7fe6038949d0>\n",
      "<function current_device at 0x7fe603715a60>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    print(\"Number of GPU:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Current Device : {torch.cuda.current_device}\")\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(torch.cuda.get_device_properties(i))\n",
    "        print(f\"Memory GB: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"GPU Allocated: {torch.cuda.memory_allocated(i) / 1024 ** 3:.2f} GB\")\n",
    "        print(f\"GPU Cached:    {torch.cuda.memory_reserved(i) / 1024 ** 3:.2f} GB\")\n",
    "        \n",
    "        \n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU detected.\")\n",
    "\n",
    "\n",
    "print(torch.cuda._get_device_index)\n",
    "print(torch.cuda.current_device)\n",
    "\n",
    "#torch.cuda.set_device(3)\n",
    "\n",
    "\n",
    "CUDA_VISIBLE_DEVICES = os.environ.get('CUDA_VISIBLE_DEVICES')\n",
    "print(CUDA_VISIBLE_DEVICES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f0fbb2-81fa-4284-a08e-f577ebbe26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar  8 09:13:35 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |\n",
      "|  0%   27C    P0             66W /  300W |   21346MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |\n",
      "|  0%   27C    P0             69W /  300W |     594MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |\n",
      "|  0%   28C    P0             68W /  300W |   22475MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   20C    P8             22W /  300W |       0MiB /  23028MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a735ff-9f84-4f5b-b859-6d9b48d25171",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a81f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.start_iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d30bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    #tokenizer=tokenizer,\n",
    "    model=model, args=training_args, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=valid_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "080edf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 1:21:46, Epoch 1/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.362900</td>\n",
       "      <td>1.449033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.121100</td>\n",
       "      <td>1.312178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=1.4783561820983886, metrics={'train_runtime': 4912.1649, 'train_samples_per_second': 0.814, 'train_steps_per_second': 0.204, 'total_flos': 2.5061788483584e+16, 'train_loss': 1.4783561820983886, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34854fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model() # this creates the config.json file etc you need to run generation tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
